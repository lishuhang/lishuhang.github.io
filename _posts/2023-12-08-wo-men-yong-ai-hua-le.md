---
layout: post
title: "我们用AI画了龙年春晚吉祥物“龙辰辰”"
date: 2023-12-08
categories: 文章
tags: [科技]
image: https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/01.png
---

人们所发现的“AI味儿”问题，即使有“三审三校”这种流程，仍然会被放过。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/01.png)

文 / 书航 2023.12.7

相信你已经看过了“龙年春晚”的吉祥物长什么样，因为它上了热搜。

12月6日，中央广播电视总台2024龙年春晚吉祥物形象“龙辰辰”正式发布亮相。

从最开始公布口号和 logo 开始，龙年春晚的宣传比平时要稍微早一点，而且这一次也摆出了非常亲民的态势。包括有人吐槽春晚小品的“包饺子”表演套路，官方微博也欣然转发，并且说“导演组正在学习了”，非常谦虚。

春晚节目难看，舞美花花绿绿大红大紫，吉祥物丑得不忍直视，相信这都是导演组可以预料到的正常反应。然而，这个“龙辰辰”发布之后，网友们对它最大的质疑却不是说它丑，而是“这怎么像是AI画的”。

这对于官方来说，可能有点“超纲”了。

12月7日凌晨，春晚官方微博发文进行回应，与此同时，还给出了一些据称拍摄自设计者电脑上的文件夹截屏，里面号称是做出这个吉祥物的源文件。

但是这些澄清目前暂时没有平息外界质疑，反而有点儿“越描越黑”的意思。

我们打算一起来探寻这些问题的答案：

根据现有信息，能否判断出这个吉祥物是不是用 AI 画的？

我们自己使用 AI，能不能画出跟这个差不多的吉祥物？

如果里面有用到 AI，但也有人类修改的元素，其中各占比多大呢？

在引用 AI 技术参与艺术创作的过程中，哪些做法是可以被大家接受的，而哪些做法是不能接受的？

## “龙辰辰”是不是AI画的？

首先，我们把目光聚焦到“龙辰辰”身上。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/02.png)

即使没有对AIGC文生图做过特别细致的研究，也可能看出图片有一种“AI味儿”，但是毕竟空口无凭。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/03.png)

听说谷歌 Bard 聊天机器人今天刚刚大升级，我们就先让它解答一下：判断一个图（特别是动物图像）是不是用AI做出来，有哪些方法？

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/04.png)

（注：Bard这次结合谷歌最新Gemini大模型的升级，只能用英语提问而不能用其他语言，才能体验。）

Bard提出以下建议：

寻找不自然的细节，例如错误放置的阴影、重复的模式或背景中的奇怪伪影。

通常看起来过于完美，具有对称的毛皮图案和无瑕的解剖结构。

动物可能显得光滑且缺乏深度感，因为AI难以生成逼真的纹理和细节。

可能以不自然的方式扭曲，或表情奇怪。

缺少眼睛中的反射、水或其他光亮表面上的倒影。

背景可能包含不一致或不合逻辑的元素，例如不可能的光线，或在半空中飘浮的物体。

确实，当我们判断一个图是不是“一眼AI”时，大致用的也是这些方法。微博用户 @CG插画控 就认为以下这些地方比较可疑：

> “第一个腿毛是螺旋设计，后腿腿毛却不沿用前腿腿毛的设计，三只腿爪数量都不同，有只耳朵的耳孔也反了。”

“第一个腿毛是螺旋设计，后腿腿毛却不沿用前腿腿毛的设计，三只腿爪数量都不同，有只耳朵的耳孔也反了。”

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/05.png)

这里有个小知识：计算爪（脚趾）的数量，五爪龙在元、明、清时代为皇帝的标志，只能由皇帝使用。其他皇室人员以及地方需要用到龙形的时候，只能使用“四爪龙”，服饰称为蟒袍，不称龙袍。也有种不严谨的说法是“五爪为龙，四爪为蛟，三爪为蟒”。

而我们的“龙辰辰”效果图里，三爪、四爪、五爪竟然都有。

好的，听说Bard对多模态的判断能力有一定的提升，识别图像那是一把好手。下面我们让Bard直接来检测“龙辰辰”是不是AI作图。

结果它说……

> “根据您发送的图像，我有信心认为这只中国龙卡通形象不是由人工智能生成的。”

“根据您发送的图像，我有信心认为这只中国龙卡通形象不是由人工智能生成的。”

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/06.png)

啊？为什么？

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/07.png)

> “人工智能生成的图像通常存在光照和反射问题。您的图像中的光照一致而逼真，龙在水中的倒影也很准确。”

“人工智能生成的图像通常存在光照和反射问题。您的图像中的光照一致而逼真，龙在水中的倒影也很准确。”

但是呢，这张图里没有水。

显然此时Bard已经陷入了“幻觉”，我们接下来还是相信人类的判断吧。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/08.png)

## 用一句话能否重现“龙辰辰”？

尽管 Bard 的判断结果不对，但是它提出的判断标准没什么错误。据此来说，我们看到的“龙辰辰”不太可能是一次生成后就直接用了。它可能是在很多次变换提示词后挑出的版本，而后期也少不了人类的手动修复。

这里有两点：

当我们尝试用一句prompt来生成龙的形象的时候，得到的结果从表面上看跟“龙辰辰”很类似，但细节方面有很多需要仔细改动的地方，是不能拿过来直接用的。

在“龙辰辰”成品图中，有一些潜在的纹路问题，体现出了有人工修复的痕迹。

要重现“龙辰辰”，首先我们来构思一个提示词。

“龙辰辰”以中国传统色“大繎、赩炽、赪霞、玉頩、春辰”绘制。总体来说，这些颜色可以概括为赭红色、橙色和金色——反正后期可以再调一下色彩。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/09.png)

综合ChatGPT和Bard的识图结果，以及我们自己对画面的判断，提示词如下：

> “一条中国的龙的卡通形象，3D材质，高清晰度，龙有较大的眼睛并微笑，鳞片有光泽，整体颜色为赭红色、橙色和金色的组合。”

“一条中国的龙的卡通形象，3D材质，高清晰度，龙有较大的眼睛并微笑，鳞片有光泽，整体颜色为赭红色、橙色和金色的组合。”

见证奇迹的时刻——我们让DALL-E 3来画一下：

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/10.png)

我们不可能1：1完全还原某张AI生图，即使用了一模一样的提示词，每次生成的结果都不一样。但这里也有一些非常有趣的发现。

首先，这些生成的龙，都以一种横向却合适的角度，被准确的塞进了一个正方形的画框里面。因为 AI 生图所生成的图片，大多数都是1:1的比例。

四条龙除了左右可能翻转之外，基本上采取的姿势跟“龙辰辰”是一样的。这说明“龙辰辰”很有可能在初始设定时使用了AI生图，作为后续修改的基础。

另一个值得注意的地方，是这些龙身上整齐的、充满光泽的鳞片。

在这个例子里，DALL-E为我们提供了4种不同的材质渲染，其中左下角的图有点像是琉璃的材质，右上角的也比较接近“龙辰辰”的鳞片。它们是整齐排列的，这说明“龙辰辰”图上整齐的鳞片，至少是理论上可以由AI一次生成。

但是，AI在理解提示词的时候，可能会有不准确的部分，而且没有办法针对某个地方进行微调，这也是 AI 生图的一个通病。

比如说，提示词中明明说的是“微笑”，然而所有的图中，龙都张开嘴大笑。之后我们试图优化提示词，说“不露出牙齿”，效果并不好。

所以很有可能，如果仅仅通过提示词，而不是垫图或其他方式，那么最终生成这个龙的图片，可能需要在为数众多的生成结果当中不断挑选。

此前一场AI创业者闭门会上，曾有实践者说，一般要获得比较好的成品图片，可能需要事先生成200~300张不同的图片，并从中挑选。曾经获得摄影比赛奖项的《太空歌剧院》，其作者之前也说，是在几百张图当中挑选出最好的一张。

除了不断试错和优化提示词，人类在“龙辰辰”这样的吉祥物诞生过程中，恐怕还需要上手来微调一些细节。

根据官方介绍，“龙辰辰”以中华民族龙图腾的代表性实物、出土于二里头遗址的绿松石龙形器筑龙面；取材首现“中国”二字的定源重器何尊，以云雷纹烙印龙腹、以扉棱雕刻龙脊；以云纹铜禁上展现古老失蜡法精湛工艺的浮雕透空云纹画龙眉、龙肩；以唐鎏金走龙挺拔雄健的背脊为昂首前行的龙鳍。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/11.png)

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/12.png)

但是当你看到这些设计灵感之后，很容易发现，它们跟实际的成图之间并没有那么明确的关联。

“云纹铜禁”是怎么进化成龙眉和龙肩的；

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/13.png)

九龙壁上的龙爪怎么进化成那个萌萌哒的爪子的；

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/14.png)

这些都很让人犯迷糊，甚至有点“牵强附会”。换句话说，我用AI做的龙也可以找出相关角度做类似的解释。

但其中一个值得注意的细节是龙腹的纹路。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/15.png)

几乎可以肯定目前的AI文生图，无法根据提示词直接生成同样的纹路。所以，这些地方相信已经经过了人类用PS进行的处理。

所以，通过我们的实战还原，我们认为情况大致有可能是这样的——或者说一种可行的路线是这样的：

这位“龙辰辰”可能是从使用 AI 工具生成的一个图作为基础来改进。人类对它进行的修剪，可能包括处理一些不对称或硬伤，将某些位置画上所需要的纹路，将背景处理为透明色，对低分辨率图像进行锐化等等。

## AI进入设计流程，有没有错？

如果简单地对比我们用同一个提示词生成的4张图片，和最后的“龙辰辰”成品，你会发现很难通过文字描述让 AI 直接听你的话。这意味着，人类可能的三个改进步骤——优化提示词、挑选图片，以及改动细节，可能实际上是非常劳心费力的过程。即使产生这个主意的第一张图是 AI，经过最后的不断测试，也有可能结果跟一开始相比完全不同。

在之前的案例当中，确实有人曾经想过完全用 AI 出一个产品图就不用改了。结果发现，要想满足商业应用各方面的要求，特别是包含 IP 和商标的一致性，要做的幕后工作有很多。有时候对它进行的修改，甚至让人有得不偿失的感觉。例如，天猫的设计部门为双11所准备的宣传图，AI节省了一部分建模的压力，但带来了新的特有的问题。

> “项目执行过程中，AI训练师的角色至关重要。在此期间，我们的AI训练师每天需要花大量的时间和精力和AI「谈笑风生」，这可比单纯拍个片、做个3d模型要费时费力多了，截止项目结束，根据AI工具的统计，我们团队总共生成了22247张图，即每一张定稿的品牌花车背后，AI训练师至少生成了400+张图片，经历了无数次的修改调试咒语。项目执行期间，根据AI工具的统计，我们每天消耗的快速时长有时候甚至长达20小时，玩过AI创作的，一定知道这个时长背后意味着什么。”

“项目执行过程中，AI训练师的角色至关重要。在此期间，我们的AI训练师每天需要花大量的时间和精力和AI「谈笑风生」，这可比单纯拍个片、做个3d模型要费时费力多了，截止项目结束，根据AI工具的统计，我们团队总共生成了22247张图，即每一张定稿的品牌花车背后，AI训练师至少生成了400+张图片，经历了无数次的修改调试咒语。项目执行期间，根据AI工具的统计，我们每天消耗的快速时长有时候甚至长达20小时，玩过AI创作的，一定知道这个时长背后意味着什么。”

所以，即使春晚团队使用了AI作为他们最初的创意来源，在这之后，要进行的“凝结在商品中的无差别的人类劳动”，那也是非常可观的。

11月底，北京互联网法院刚刚就一起“人工智能生成图片著作权侵权纠纷”作出一审判决，认为涉案图片可以主张著作权。法院认定，原告在生成图片过程中进行了智力投入，包括设计提示词、参数和选择最终图片等，因此图片具备智力成果要件。

尽管该案很可能只是个例，不具备一般指导意义，但人类在优化提示词、挑选图片、改动细节方面的劳动是不能被忽略的。

一张AI生成的图到最后能使用的商业IP，还包括其他复杂的过程，例如将其三维化，应用在片头、虚拟棚等不同的场合。兔年的春晚吉祥物“兔圆圆”在晚会片头动画当中，是以一个完全3D建模的形象出现的，包括全身的位置都做了相关渲染。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/16.png)

更不用说，如果需要卖相关文创产品，那么自然就涉及到衍生品的设计。像之前韩美林创作的“猴塞雷”，在做成公仔时也经过了二次设计。

事实上，总台文创对这一次的“龙辰辰”已经有了一个初步的公仔设计样本。当然很值得人们吐槽的，就是这个龙好像劣化了很多，完全没有把3D效果图的风采展现出来，可以说判若两龙。

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/17.png)

（当然这个实物展示无意中解答了上面的一个遗留问题：咱这条龙的脚趾数量，正确答案是“四爪”。）

![](https://lishuhang.me/img/2023/12/08/wo-men-yong-ai-hua-le/18.png)

哎，所以说，如果平面图案也是按照这个公仔的样子来的话，丑就丑了点，肯定没人会怀疑它是用AI生成的……

我们对待AIGC的态度始终如一，希望人类能认可AI生产的内容，而不是仅仅听到AI两个字就退避三舍。今年早些时候，迪士尼使用AI生成美剧片头引发争议时，我们也有过相关的评论。

现在文生图已经用在对质量要求不那么严格的领域，例如自媒体文章配图。假如技术进步到真假难辨的程度，它用于商业化文艺作品，就像“人造钻石”自然替代天然钻石一样，有什么不可以的呢？

但这里面其实存在一个隐患。人们更倾向于直接相信和采用 AI 生成的结果，他们甚至会对这个 AI 生图越看越顺眼，因此之后修改也可能发现不了太多，即使是增加了审核环节也很难避免。

所以，在画面走向公众之后，人们所发现的“AI味儿”实际上是那些AI可能会犯，但人类画师通常会避免的问题，例如一只耳朵的朝向感觉不对，两条腿的纹路不对称等等。这些问题，可能在初始图片已经有个心理锚点的时候，即使有“三审三校”这种流程，仍然会被放过。

尽管大模型和文生图从诞生的第一时间，就有幻觉的问题，但是它的对话形态，以及能快速生成结果的自信，都使得人们有意无意忽略了这种隐患。

实际上，真正用过 AI 的人就会知道，不管是让他总结一篇文章或 PDF，还是搜索网上的数据并摘要，都会或多或少有一些不可被人信任的地方。

所以，越是重度使用和依赖 AI 的人，就越应该在其中加入更多人工检查的部分，而不是相反。如果主动放弃了核查和校对过程，就是完全将人类的智慧和判断力拱手让给了 AI，这样就一定会出现问题。

首发于视智未来