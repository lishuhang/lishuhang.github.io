---
layout: post
title: "能上网，能识图，能做图，ChatGPT的完全体有多神奇"
date: 2023-10-12
categories: 文章
tags: [科技]
image: https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/01.png
---

文 / 书航 2023.10.12

本文首发于公众号“视智未来”

Hello各位打工人！现在相信有一个问题非常困扰大家：

今天到底星期几？

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/01.png)

踏入连休之后的7天班，不论是早上被设定的好多个闹钟群殴，还是假装在电脑前聚精会神，心思却跑到了九霄云外。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/02.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/03.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/04.png)

上面这些由藤子·不二雄、鸟山明等日本泰斗级漫画家带来的画作，肯定都能充分描绘你的现状吧。

——哦，有一点我说错了，上面这几幅画并不是由那些漫画家本人画出来的。创作它们的是内置了DALL-E 3的ChatGPT Plus。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/05.png)

虽然不是为了给祖国母亲生日献礼，但OpenAI确实是在刚刚过去的长假里面，对Plus用户灰度开放了下列新功能：

用必应搜索的能力，此前因效果不佳临时下线，此番重新恢复；

默认模式允许上传图片，并且识别图片内容；

加入了DALL-E 3文生图模式。

其中，DALL-E 3还没有普及到所有ChatGPT Plus订户中，不过我手中的账号已经是开通了上述所有能力的“完全体”了。

有的Plus用户虽然续了费，但是并不能见到上面所有这些功能。此时，阅读我们下面这篇简单的介绍和上手指南就非常重要了。

可以说，这里面每一个能力都是这大半年以来ChatGPT的用户们期待已久的。但是它们实际上的效果如何，是否可以真正融入我们的日常工作流当中，又会不会对市场上的竞品构成重大的威胁呢？

不论是科普，评测还是培训，我们始终坚持一个原则：就像在实际的生产过程一样来测试和使用AI工具，而不是单纯追求让它“炫技”。

是骡子是马，我们现在就拉出来遛遛。

## 必应搜索

在进入大家都很关心的图像能力之前，先来看下恢复上线的必应联网模块。

上个月，娱乐资本论刚刚完成了第二轮文本大模型实用场景横评。读者们应该记得，在那次测试中，GPT-4不联网时的表现依然稳定，然而当它使用VoxScript等插件联网时，效果却比一些国产大模型的表现还要差。

我们也分析了相关的原因，主要是官方与必应合作的联网插件不能使用时，其他第三方插件的表现不稳定，而且参差不齐。

这次官方联网的回归，让我们期望它会有比以前更好的表现，但实际上并没有好太多，很难称得上提供了全面和准确的答案。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/06.png)

而且，与使用插件联网不同，这里不再允许你查看它在回答问题时具体访问了哪些网站。所以，结果不理想时也无法找出原因。

当然，GPT支持更长的提示词和答案生成，而必应只支持几百个字的短答案，但联网还会占用GPT-4每3个小时50次的限额。所以有时你在必应官网用AI搜索，效果可能更好一些。

所以就是这样，让我们赶紧进入下面的重头戏。

## DALL-E 3绘图

现在我们可以回顾一下本文开头的三张图。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/07.jpg)

这三张图的最终效果都非常出色，可以说在这次更新之前，所有的文生图工具中，只有Midjourney能够达到这种水平。当然我们一直认为竞争对手达到MJ的高度是迟早的事情，但DALL-E 3的出现比我们想象的早得多。

当然，在ChatGPT中引入图片生成，最大的改进不仅在于生成的效果，还在于生成的过程。

我们知道与文字相比，无论是SD还是MJ的提示词，都更不能随便写，它们有更多规则、格式乃至“咒语”的要求，在生成图片时起到了重要作用。像我们的AIGC大师课中就指出，有些绘画风格、艺术家名称、效果光线等都需要指定，而这些词汇所酝酿出的结果就像炼丹一样。

在如今的ChatGPT里面，这些已经是过去的事情了。我们现在所使用的方法，会更接近要求一位人类画师去做事，说的话也更接近自然语言，GPT-4承担了转译的工作。

ChatGPT会根据用户的需求，一次提供四个不同的真·提示词，并将它们导入DALL-E中生成四张不同的图片。这比单一提示词生成四种变体更完善，还可以指定其中一张继续进行微调，尽管效果不一定如人意。

让我们来回顾文章开头的画作是怎样生成的。

首先，当我们看到一张梗图很有趣，于是想自己画一张的时候，这是非常常见的使用场景。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/08.jpg)

不过，在DALL-E 3之前，我们似乎难以想象除了Midjourney还有什么文生图工具可以出来比较好的效果。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/09.png)

点开可以发现，每一张图的prompt都各不相同。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/10.png)

尽管AI作图嵌字问题还是没完全解决，但你可以看出跟之前版本相比有了巨大的进步。此时我们甚至可以只用Windows自带的“画图”来给它加上适当的字体。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/11.jpg)

其它图片也类似：

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/12.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/13.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/14.png)

很显然，如果我们想使用传统文生图方法，生成提示词是需要我们自己动脑的事情，但现在GPT已经承担了这个重任。当你点击具体的图片时，可以看到它使用了哪些提示词，并将其复制下来。在生成结果出现问题时，也可以通过分析提示词构成来发现问题所在，以及是否有可能改进。

由于成图的完成度非常高，图像裁切不需要的部分，以及往里面嵌字，甚至只需要使用Windows自带的画图就可以完成。

在下面的测试中，我们发现，如果你的指令非常简单，ChatGPT生成的作品或许有一些对东亚文化元素的刻板印象和挪用。例如：

请创作一幅中国庆祝三·八国际劳动妇女节的海报。主题是：“巾帼筑梦心向党，强国复兴勇担当”，但不需要在海报中出现文字。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/15.jpg)

接下来，我们尝试用必应搜索给我们总结，怎样优化提示词，让生成效果更贴近我们的需要。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/16.jpg)

尽管如此，如果你直接让ChatGPT改图，它依然大概率不会按照你的要求直接改动，这反映了DALL-E 3在识别prompt方面的局限。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/17.jpg)

如果你点开它更改过的prompt，就会发现不是提示词的问题，GPT实际上已经尽力了。所以，一次生成的图最好还是由人工在后期改动。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/18.png)

> oil painting of a modern Shanghai ballerina, gracefully posing in front of iconic landmarks near the Bund. In the background, there's a plain red flag without any emblems, stars, or symbols, fluttering in the wind. The scene is dominated by red and gold hues, and a clear space at the bottom is reserved for potential text.

oil painting of a modern Shanghai ballerina, gracefully posing in front of iconic landmarks near the Bund. In the background, there's a plain red flag without any emblems, stars, or symbols, fluttering in the wind. The scene is dominated by red and gold hues, and a clear space at the bottom is reserved for potential text.

即使如此，我们也已经得到了几张最终效果很好的图片。

上述试用过程代表了一个总体趋势，即prompt微调的作用大大降低，我们文生图给AI下的指令将会越来越接近自然语言。

## GPT-4 识图

另一个最受欢迎的ChatGPT新功能，当然就是识别图片的含义。

在一些近期的测试中，GPT-4是可以读出一些幽默或者寓言故事中的潜台词，分析画面当中人物的心理和情绪。当然，这些都是重大的突破，但总体来说还是属于“常规动作”。

我们想看看它还能不能做更好玩的事情－－比如看X光片。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/19.png)

医学影像行业是不是要被替代掉了？实际结果远远没有这么乐观。

我给了GPT一张有问题的X光片（这里不放原图，因为那是我自己的X光片），人类医生可以看到一颗劈裂牙和右下颌骨的一块含牙囊肿，但GPT并没有识别出任何问题。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/20.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/21.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/22.png)

回头看一下上面那张网图，它的问题是一样的，它知道这是牙片，但除此之外就没有然后了，它倾向于对看不出来、不确定的东西报喜不报忧，这点倒是跟“百度一下，我觉得我快挂了”完全相反。

看来，影像科室里看片的人类，目前还可以继续高枕无忧。

在不这么严肃的问题上，比如翻译一个外文广告牌，是可以胜任的。你可以将这个结果跟Jina.AI的同款产品做个对比。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/23.jpg)

翻译确实是ChatGPT的长项，图片识别更是让这一长处如虎添翼。不过，它具体胜任到什么程度，又取决于它基础知识的积累，在不那么熟悉的领域，比如翻译维吾尔文，照样“一本正经地胡说八道”。

接下来的测试在效果上可谓非常惊艳。我们在一个设计师常用的网站Dribbble上找了一些网页和APP的效果图，然后让它直接生成一个在浏览器中真的能打开的网页代码。

它完成了这个任务－－非常出色。

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/24.png)

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/25.png)

虽然没有完全复刻效果图，但如果我完全不会前端代码，又想从零开始做，那么它已经能让我做出一个可用的东西。甚至因为它的实现与效果图中细微的区别，还可以说它给原作“洗稿”了。这可能是运用GPT的发散思维能力的一个最佳案例。

经过4-5次提示词调整后，成品如下：

![](https://lishuhang.me/img/2023/10/12/neng-shang-wang-neng-shi-tu/26.png)

可以说，动嘴修改的成功率远高于之前预想，而且再怎么说，也比不断微调代码要简单多了。这样一来，各位文字工作者们可以用前所未有的简单方法，来试着搭建自己的作品集或个人网站。

## 谁要慌了？

回头再看一看我们所做过的这些测试：

不需要懂英文，就可以用自然语言让DALL-E 3作画，效果逼近Midjourney；

可以识图、在热门语言之间翻译图像内容；

将一个画出来的界面图转换为真正的网页，不会前端技术也可以设计自己的网站……

这些进化，给人最大的感受就是意料之外，情理之中。仔细一思考就会发现，这些功能只是对原本GPT-4基础能力的巧妙运用，将原本相互分离的不同模态结合在一起，就化腐朽为神奇了。

在识图和绘图时，GPT仍然会瞎编，因此仍然需要你的专业知识来补充那些它不掌握的领域，做事实核查，并决定如何剪裁和应用它的回答。

这进一步强化了我们对GPT的理解，它是一个为现有从业者提供的工具，可以增强你现有的能力，但不能自主产生知识，只能根据你的思路进行操作。

ChatGPT不会取代我们的大多数读者，但是会更好地帮助我们。但是，当然也会有人看到这些进步之后感受到真实的恐慌。

比如我们一直在对比的Midjourney本尊：对于普通用户，既然手头已经有一个效果上与MJ相差不多的工具，数量又几乎没有限制，还不用额外掏钱，那为什么还要再买MidJourney呢？这种搭配组合将用户更深度地绑定在OpenAI的体系内，也让GPT每月20美元的月费变得越来越物超所值。

比如各种国产大模型的开发者：作图精度，语义理解这些，目前ChatGPT都是几个最强的合在一起，让GPT与国产大模型之间的差距似乎成了更加难以逾越的天堑。但是，开源领域仍然可以继续追赶，类似于LLaMa的图片应用LLaVA也出现了。

比如第三方整合各家服务的开发者们，可能需要重新思考自己的开发方向。例如，趁着不是所有大模型都有多模态的空当，可以在第三方应用中被智能地调用最适合的模型，以执行相关任务。这样，用户将能够使用各个领域中的最优解，之前采访过的Jina就是正在做这样的工作。

我们期待第一方或者第三方服务，可以将现有分散在不同模态上的能力真正的组合起来，而不是说互相独立地放置。

ChatGPT的进步说明，Openai或MJ树立起来的壁垒并不是绝对无法攻破的，只是后来者需要花费几个月、半年或一年的时间差来赶超。对于后来者来说，坚持下去而不倒闭，可能就是胜利的关键。